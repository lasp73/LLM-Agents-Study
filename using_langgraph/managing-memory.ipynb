{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerenciando memória (rascunho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta parte, quero examinar um pouco o gerenciamento da memória do agente. Não se trata de memória ocupada, trata-se do conhecimento acumulado pelo agente, especificamente a questão de um longo histórico de diálogo, considerando a limitação de entrada dos LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregue variáveis de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acesso ao LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure o LangChain para usar o LLM desejado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_ollama import ChatOllama\n",
    "\n",
    "# llm = ChatOllama(\n",
    "#     model=\"llama3.2\", \n",
    "#     temperature=0.0, \n",
    "#     max_tokens=1000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\", \n",
    "    temperature=0.0, \n",
    "    max_tokens=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histórico da conversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"\n",
    "Você é uma assistente virtual amistosa e sempre disposta a ajudar.\n",
    "Seu nome é Ana. Você atende clientes da empresa ACME.\n",
    "\n",
    "Siga sempre as instruções abaixo:\n",
    "\n",
    "- APENAS na sua primeira mensagem enviada ao cliente:\n",
    "  fale o nome do cliente e deseje 'bom dia', 'boa tarde' ou 'boa noite', de acordo com o horário atual.\n",
    "  Por exemplo: 'Bom dia, <nome do cliente>!'\n",
    "- Dê respostas concisas.\n",
    "- Utilize apenas as informações mencionadas na conversa para responder perguntas.\n",
    "\n",
    "Informações gerais:\n",
    "\n",
    "- Horário atual: 22:09:45\n",
    "- Data atual: Monday, 2025-04-28\n",
    "\n",
    "Informações do cliente:\n",
    "\n",
    "- Nome: José da Silva\n",
    "- Localização atual: Campinas, São Paulo\n",
    "- Comidas preferidas: vegetariana\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui a simulação de um histórico de conversa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = \"\"\"\n",
    "================================ Human Message =================================\n",
    "\n",
    "Você pode recomendar um restaurante para mim?\n",
    "\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Olá, José da Silva!\n",
    "\n",
    "Infelizmente, não tenho informações específicas sobre restaurantes na sua localização atual em Campinas. Posso sugerir que você procure por opções de restaurante vegetariana no Google ou em aplicativos de entrega de comida para encontrar algo adequado às suas preferências.\n",
    "\n",
    "Se precisar de mais ajuda, estou à disposição!\n",
    "\n",
    "================================ Human Message =================================\n",
    "\n",
    "Hoje é meu aniversário e quero ir a um cinema também. Aliás, eu gosto muito de cinema e teatro. Mas olha, agora estou em São José dos Campos. \n",
    "\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Feliz aniversário!\n",
    "\n",
    "São José dos Campos tem várias opções de cinemas e teatros. Você pode procurar por cinemas como o Cineplex ou o Cinemex, que oferecem uma experiência de cinema de alta qualidade.\n",
    "\n",
    "Se precisar de mais ajuda para encontrar opções de entretenimento, estou à disposição!\n",
    "\n",
    "================================ Human Message =================================\n",
    "\n",
    "Bom, mas eu preciso sacar dinheiro. Eu tenho conta no banco do brasil. Tem algum Banco do Brasil aqui na cidade?\n",
    "\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Sim, há vários agências do Banco do Brasil em São José dos Campos. Você pode procurar por agências próximas à sua localização atual ou verificar o site do Banco do Brasil para encontrar a agência mais próxima.\n",
    "\n",
    "Se precisar de ajuda para encontrar uma agência, posso tentar ajudar!\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo da conversa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora o tamanho máximo da entrada dos LLMs tenha aumentado significativamente, ele não é infinito e alguns LLMs ainda tem uma entrada máxima que pode ser menor que o histórico de uma longa conversa.\n",
    "\n",
    "Uma estratégia é usar um LLM para resumir a conversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aqui está um resumo dos pontos principais em um parágrafo:\n",
      "\n",
      "O usuário pediu recomendações para um restaurante, mas o assistente não tinha informações específicas sobre a localização atual do usuário em Campinas. Em seguida, o usuário revelou que estava em São José dos Campos e queria ir ao cinema para comemorar seu aniversário. O assistente sugeriu cinemas como Cineplex e Cinemex e ofereceu ajuda para encontrar opções de entretenimento. Além disso, o usuário precisava sacar dinheiro e o assistente informou que há várias agências do Banco do Brasil em São José dos Campos, sugerindo que o usuário procure por agências próximas ou verifique o site do banco.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"A partir da conversa abaixo, faça um resumo dos pontos principais em apenas um parágrafo:\n",
    "\n",
    "{history}\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt.format(history = chat_history))\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraindo informações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra abordagem é tentar gerenciar as informações mais importantes e guardá-las de forma mais estruturada.\n",
    "\n",
    "Um LLM pode ser usado para extrair informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A lista de informações do cliente que podem ser extraídas da conversa é:\n",
      "\n",
      "1. Nome: José da Silva\n",
      "2. Localização atual: São José dos Campos (anteriormente estava em Campinas)\n",
      "3. Data de nascimento: não especificada, mas é o dia da conversa (aniversário)\n",
      "4. Interesses: cinema, teatro\n",
      "5. Preferências alimentares: vegetariana\n",
      "6. Banco: Banco do Brasil (tem conta)\n",
      "\n",
      "Essas informações podem ser úteis para personalizar a experiência do cliente e oferecer recomendações mais relevantes em futuras interações.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Apresente a lista de informações do cliente que podem ser extraídas da conversa abaixo:\n",
    "\n",
    "{history}\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt.format(history = chat_history))\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos extrair as informações da conversa de maneira estruturada, usando o recurso de *structured output*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CustomerInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">nome</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'José da Silva'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">data_aniversario</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2025-04-28'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">endereco</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">telefone</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">bancos</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Banco do Brasil'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">localizacao_atual</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'São José dos Campos'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">comidas_preferidas</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'vegetariana'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">diversoes_preferidas</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'cinema'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'teatro'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mCustomerInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mnome\u001b[0m=\u001b[32m'José da Silva'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mdata_aniversario\u001b[0m=\u001b[32m'2025-04-28'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mendereco\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mtelefone\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mbancos\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Banco do Brasil'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mlocalizacao_atual\u001b[0m=\u001b[32m'São José dos Campos'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mcomidas_preferidas\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'vegetariana'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mdiversoes_preferidas\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'cinema'\u001b[0m, \u001b[32m'teatro'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from rich.pretty import pprint\n",
    "\n",
    "\n",
    "prompt = \"\"\"Você deve analisar atentamente a conversa indicada abaixo.\n",
    "Extraia todas as informações do cliente mencionadas nessa conversa.\n",
    "Atualize as \"informações anteriores\"\n",
    "Finalemnte, retorne as informações atualizadas.\n",
    "\n",
    "### CONVERSA\n",
    "\n",
    "{history}\n",
    "\n",
    "### INFORMAÇÕES ANTERIORES\n",
    "\n",
    "{information}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class CustomerInfo(BaseModel):\n",
    "    nome: str = Field(description=\"Nome do cliente\")\n",
    "    data_aniversario: str = Field(\n",
    "        description=\"Data de aniversário do cliente\", default=\"\"\n",
    "    )\n",
    "    endereco: str = Field(description=\"Endereço do cliente\", default=\"\")\n",
    "    telefone: str = Field(description=\"Telefone do cliente\", default=\"\")\n",
    "    bancos: List[str] = Field(\n",
    "        description=\"Bancos nos quais o cliente tem conta\", default=[]\n",
    "    )\n",
    "    localizacao_atual: str = Field(\n",
    "        description=\"Localização atual do cliente\", default=\"\"\n",
    "    )\n",
    "    comidas_preferidas: List[str] = Field(description=\"Comidas preferidas\", default=[])\n",
    "    diversoes_preferidas: List[str] = Field(\n",
    "        description=\"Diversões preferidas\", default=[]\n",
    "    )\n",
    "\n",
    "\n",
    "llm_struct_output = llm.with_structured_output(CustomerInfo)\n",
    "\n",
    "response = llm_struct_output.invoke(\n",
    "    prompt.format(history=chat_history, information=system_prompt)\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
