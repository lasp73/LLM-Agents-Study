{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gerenciando memória (rascunho)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesta parte, quero examinar um pouco o gerenciamento da memória do agente. Não se trata de memória ocupada, trata-se do conhecimento acumulado pelo agente, especificamente a questão de um longo histórico de diálogo, considerando a limitação de entrada dos LLMs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregue variáveis de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acesso ao LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure o LangChain para usar o LLM desejado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_ollama import ChatOllama\n",
    "\n",
    "# llm = ChatOllama(\n",
    "#     model=\"llama3.2\", \n",
    "#     temperature=0.0, \n",
    "#     max_tokens=1000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\", \n",
    "    temperature=0.0, \n",
    "    max_tokens=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histórico da conversa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_info = \"\"\"\n",
    "- Nome: José da Silva\n",
    "- Localização atual: Campinas, São Paulo\n",
    "- Comidas preferidas: vegetariana\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aqui a simulação de um histórico de conversa:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = \"\"\"\n",
    "Horário da conversa: 22:09:45\n",
    "Data da conversa: Monday, 2025-04-28\n",
    "\n",
    "================================ Human Message =================================\n",
    "\n",
    "Você pode recomendar um restaurante para mim?\n",
    "\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Olá, José da Silva!\n",
    "\n",
    "Infelizmente, não tenho informações específicas sobre restaurantes na sua localização atual em Campinas. Posso sugerir que você procure por opções de restaurante vegetariana no Google ou em aplicativos de entrega de comida para encontrar algo adequado às suas preferências.\n",
    "\n",
    "Se precisar de mais ajuda, estou à disposição!\n",
    "\n",
    "================================ Human Message =================================\n",
    "\n",
    "Hoje é meu aniversário e quero ir a um cinema também. Aliás, eu gosto muito de cinema e teatro. Mas olha, agora estou em São José dos Campos. \n",
    "\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Feliz aniversário!\n",
    "\n",
    "São José dos Campos tem várias opções de cinemas e teatros. Você pode procurar por cinemas como o Cineplex ou o Cinemex, que oferecem uma experiência de cinema de alta qualidade.\n",
    "\n",
    "Se precisar de mais ajuda para encontrar opções de entretenimento, estou à disposição!\n",
    "\n",
    "================================ Human Message =================================\n",
    "\n",
    "Bom, mas eu preciso sacar dinheiro. Eu tenho conta no banco do brasil. Tem algum Banco do Brasil aqui na cidade?\n",
    "\n",
    "================================== Ai Message ==================================\n",
    "\n",
    "Sim, há vários agências do Banco do Brasil em São José dos Campos. Você pode procurar por agências próximas à sua localização atual ou verificar o site do Banco do Brasil para encontrar a agência mais próxima.\n",
    "\n",
    "Se precisar de ajuda para encontrar uma agência, posso tentar ajudar!\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resumo da conversa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Embora o tamanho máximo da entrada dos LLMs tenha aumentado significativamente, ele não é infinito e alguns LLMs ainda tem uma entrada máxima que pode ser menor que o histórico de uma longa conversa.\n",
    "\n",
    "Uma estratégia é usar um LLM para resumir a conversa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aqui está um resumo dos pontos principais da conversa: O usuário pede recomendações para um restaurante, mas o AI não tem informações específicas sobre a localização atual do usuário em Campinas, sugerindo que ele procure opções online. Em seguida, o usuário revela que está em São José dos Campos e quer ir ao cinema, então o AI sugere opções de cinemas de alta qualidade na cidade. Por fim, o usuário precisa sacar dinheiro e pergunta se há agências do Banco do Brasil em São José dos Campos, e o AI confirma que sim, sugerindo que ele procure por agências próximas ou verifique o site do banco.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"A partir da conversa abaixo, faça um resumo dos pontos principais em apenas um parágrafo:\n",
    "\n",
    "{history}\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt.format(history = chat_history))\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraindo informações"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Outra abordagem é tentar gerenciar as informações mais importantes e guardá-las de forma mais estruturada.\n",
    "\n",
    "Um LLM pode ser usado para extrair informações."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aqui está a lista de informações do cliente que podem ser extraídas da conversa:\n",
      "\n",
      "1. **Nome**: José da Silva\n",
      "2. **Localização atual**: São José dos Campos (anteriormente estava em Campinas)\n",
      "3. **Data de nascimento**: 28 de abril de 2025 (dia da conversa)\n",
      "4. **Interesses**: Cinema e teatro\n",
      "5. **Necessidades**: Encontrar um restaurante, um cinema e uma agência do Banco do Brasil em São José dos Campos\n",
      "6. **Banco**: Banco do Brasil (possui conta)\n",
      "\n",
      "Essas informações podem ser úteis para personalizar a experiência do cliente e oferecer recomendações mais precisas e relevantes.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"Apresente a lista de informações do cliente que podem ser extraídas da conversa abaixo:\n",
    "\n",
    "{history}\n",
    "\"\"\"\n",
    "\n",
    "response = llm.invoke(prompt.format(history = chat_history))\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos extrair as informações da conversa de maneira estruturada, usando o recurso de *structured output*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">CustomerInfo</span><span style=\"font-weight: bold\">(</span>\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">nome</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'José da Silva'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">data_aniversario</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'2025-04-28'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">endereco</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">telefone</span>=<span style=\"color: #008000; text-decoration-color: #008000\">''</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">bancos</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'Banco do Brasil'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">localizacao_atual</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'São José dos Campos'</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">comidas_preferidas</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'vegetariana'</span><span style=\"font-weight: bold\">]</span>,\n",
       "<span style=\"color: #7fbf7f; text-decoration-color: #7fbf7f\">│   </span><span style=\"color: #808000; text-decoration-color: #808000\">diversoes_preferidas</span>=<span style=\"font-weight: bold\">[</span><span style=\"color: #008000; text-decoration-color: #008000\">'cinema'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'teatro'</span><span style=\"font-weight: bold\">]</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mCustomerInfo\u001b[0m\u001b[1m(\u001b[0m\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mnome\u001b[0m=\u001b[32m'José da Silva'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mdata_aniversario\u001b[0m=\u001b[32m'2025-04-28'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mendereco\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mtelefone\u001b[0m=\u001b[32m''\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mbancos\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'Banco do Brasil'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mlocalizacao_atual\u001b[0m=\u001b[32m'São José dos Campos'\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mcomidas_preferidas\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'vegetariana'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "\u001b[2;32m│   \u001b[0m\u001b[33mdiversoes_preferidas\u001b[0m=\u001b[1m[\u001b[0m\u001b[32m'cinema'\u001b[0m, \u001b[32m'teatro'\u001b[0m\u001b[1m]\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from rich.pretty import pprint\n",
    "\n",
    "\n",
    "prompt = \"\"\"Você deve analisar atentamente a conversa indicada abaixo.\n",
    "Extraia todas as informações do cliente mencionadas nessa conversa.\n",
    "Atualize as \"informações anteriores\"\n",
    "Finalmente, retorne as informações atualizadas.\n",
    "\n",
    "### CONVERSA\n",
    "\n",
    "{history}\n",
    "\n",
    "### INFORMAÇÕES ANTERIORES\n",
    "\n",
    "{information}\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "class CustomerInfo(BaseModel):\n",
    "    nome: str = Field(description=\"Nome do cliente\")\n",
    "    data_aniversario: str = Field(\n",
    "        description=\"Data de aniversário do cliente\", default=\"\"\n",
    "    )\n",
    "    endereco: str = Field(description=\"Endereço do cliente\", default=\"\")\n",
    "    telefone: str = Field(description=\"Telefone do cliente\", default=\"\")\n",
    "    bancos: List[str] = Field(\n",
    "        description=\"Bancos nos quais o cliente tem conta\", default=[]\n",
    "    )\n",
    "    localizacao_atual: str = Field(\n",
    "        description=\"Localização atual do cliente\", default=\"\"\n",
    "    )\n",
    "    comidas_preferidas: List[str] = Field(description=\"Comidas preferidas\", default=[])\n",
    "    diversoes_preferidas: List[str] = Field(\n",
    "        description=\"Diversões preferidas\", default=[]\n",
    "    )\n",
    "\n",
    "\n",
    "llm_struct_output = llm.with_structured_output(CustomerInfo)\n",
    "\n",
    "response = llm_struct_output.invoke(\n",
    "    prompt.format(history=chat_history, information=customer_info)\n",
    ")\n",
    "\n",
    "pprint(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "using_langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
