{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot com LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregue variáveis de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure o LangChain para usar o LLM desejado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_ollama import ChatOllama\n",
    "\n",
    "# llm = ChatOllama(\n",
    "#     model=\"llama3.2\", \n",
    "#     temperature=0.0, \n",
    "#     max_tokens=2000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_cerebras import ChatCerebras\n",
    "# llm = ChatCerebras(\n",
    "#     model=\"llama-3.3-70b\",\n",
    "#     temperature=0.0,\n",
    "#     max_tokens=2000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_groq import ChatGroq\n",
    "# llm = ChatGroq(\n",
    "#     model=\"qwen-qwq-32b\", \n",
    "#     temperature=0.0, \n",
    "#     max_tokens=2000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "llm = ChatGroq(\n",
    "    model=\"llama3-70b-8192\", \n",
    "    temperature=0.0, \n",
    "    max_tokens=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_groq import ChatGroq\n",
    "# llm = ChatGroq(\n",
    "#     model=\"llama3-8b-8192\", \n",
    "#     temperature=0.0, \n",
    "#     max_tokens=2000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ferramentas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ferramentas externas usadas pelo agente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ferramenta de busca na internet:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "# tools.append(TavilySearchResults(max_results=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ferramenta de busca FAKE:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def search(query):\n",
    "    \"\"\"A search tool used to get information.\n",
    "\n",
    "    Args:\n",
    "        query: The query to search for.\n",
    "        \n",
    "    Returns:\n",
    "        str: The result of the search.\"\"\"\n",
    "    \n",
    "    if \"campinas\" in query.lower():\n",
    "        return \"Em 2022, a população de Campinas foi estimada pelo Instituto Brasileiro de Geografia e Estatística em 1.139.047 habitantes.\"\n",
    "    elif \"são paulo\" in query.lower():\n",
    "        return \"A cidade de São Paulo tem uma população estimada de 11.895.578 habitantes em 2024. Essa população faz de São Paulo a maior cidade do Brasil e uma das mais populosas do mundo. \"\n",
    "    else:\n",
    "        return \"Informação não encontrada. Tente consultar de outra forma.\"\n",
    "\n",
    "tools.append(search)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculadora:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "\n",
    "@tool\n",
    "def calculate(expression):\n",
    "    \"\"\"A calculator tool that can perform basic arithmetic operations. Use this when you need to compute mathematical expressions or solve numerical problems.\n",
    "\n",
    "    Args:\n",
    "        expression: The mathematical expression to evaluate.\n",
    "        \n",
    "    Returns:\n",
    "        str: The result of the calculation.\"\"\"\n",
    "\n",
    "    expression = re.sub(r'[^0-9+\\-*/().]', '', expression)\n",
    "    \n",
    "    try:\n",
    "        result = eval(expression)\n",
    "        return str(result)\n",
    "    except (SyntaxError, ZeroDivisionError, NameError, TypeError, OverflowError):\n",
    "        return \"Error: Invalid expression\"\n",
    "\n",
    "tools.append(calculate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina o template do prompt de sistema do chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"Você é uma assistente capaz de resolver problemas usando as ferramentas disponíveis.\n",
    "Resolva o problema apresentado passo-a-passo.\n",
    "No final, dê a resposta ao problema de forma concisa e completa.\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def make_system_prompt():\n",
    "    return prompt_template"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina o código do chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "class ChatbotState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "\n",
    "\n",
    "def chatbot_node(state: ChatbotState):\n",
    "    prompt = [SystemMessage(make_system_prompt())] + state[\"messages\"]\n",
    "    response = llm_with_tools.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "builder = StateGraph(ChatbotState)\n",
    "builder.add_node(\"chatbot\", chatbot_node)\n",
    "builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "builder.add_conditional_edges(\"chatbot\", tools_condition)\n",
    "builder.add_edge(\"tools\", \"chatbot\")\n",
    "\n",
    "builder.set_entry_point(\"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "# display(Image(graph.get_graph(xray=True).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código para facilitar o uso do chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(message: str, session_id=\"1\"):\n",
    "    config = {\"recursion_limit\": 10, \"configurable\": {\"thread_id\": session_id}}\n",
    "    messages = {\"messages\": [HumanMessage(content=message)]}\n",
    "    index = -1\n",
    "    for event in graph.stream(messages, config=config, stream_mode=\"values\"):\n",
    "        for msg in event[\"messages\"][index:]:\n",
    "            msg.pretty_print()\n",
    "            print(\"\\n\")\n",
    "        index = len(event[\"messages\"])\n",
    "\n",
    "def clear_memory():\n",
    "    memory.storage.clear()\n",
    "\n",
    "def show_history(session_id=\"1\"):\n",
    "    config = {\"configurable\": {\"thread_id\": session_id}}\n",
    "    for msg in graph.get_state(config).values[\"messages\"]:\n",
    "        msg.pretty_print()\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversando com o chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()\n",
    "chatbot(\"Qual a população atual de Campinas?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()\n",
    "chatbot(\"Quanto é o dobro de 3.14?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_memory()\n",
    "chatbot(\"Quanto é a razão entre a população da cidade de São Paulo e a população de Campinas?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
