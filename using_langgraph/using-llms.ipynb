{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VERUqjejmZ51"
      },
      "source": [
        "Usando `pipeline` da biblioteca Transformers:\n",
        "\n",
        "https://huggingface.co/docs/transformers/main/en/chat_templating"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "46F2dPkNmGBC",
        "outputId": "e195979a-b438-40f4-cb10-adbef5b81c8a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Device set to use cuda:0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'generated_text': [{'role': 'user', 'content': 'Who are you?'},\n",
              "   {'role': 'assistant',\n",
              "    'content': '<think>\\nOkay, the user is asking, \"Who are you?\" I need to respond appropriately. Let me think about how to approach this.\\n\\nFirst, I should acknowledge their question. It\\'s a good start to show I\\'m here to help. I can say, \"Hi there! I\\'m a virtual assistant. What can I assist you with today?\" That\\'s friendly and opens the door for more information.\\n\\nI should also make sure to be helpful and offer assistance. Maybe add something like, \"Feel free to ask anything!\" to keep the conversation going. \\n\\nI need to keep the tone positive and approachable. Avoid any technical jargon. Keep it simple and conversational. Let me check if there\\'s anything else I should include. No, I think that\\'s all. Let\\'s put it all together into a natural response.\\n</think>\\n\\nHi there! I\\'m a virtual assistant. What can I assist you with today? Feel free to ask anything! üòä'}]}]"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"Qwen/Qwen3-0.6B\", max_new_tokens=2000)\n",
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"Who are you?\"},\n",
        "]\n",
        "pipe(messages)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "LHbnMQ_YmXoG"
      },
      "outputs": [],
      "source": [
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"Qwen/Qwen3-0.6B\")\n",
        "model = AutoModelForCausalLM.from_pretrained(\"Qwen/Qwen3-0.6B\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "ehjWNB9Wnfmg",
        "outputId": "0b9c6282-5835-4270-f4c3-de69eb11b84e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Who are you? What is your purpose in this role?\\n\\nAs an AI assistant, I do not have a physical form or consciousness. I am an AI that can assist you in various ways, such as answering questions, providing information, and helping with tasks. My purpose in this role is to provide'"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"Who are you?\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate\n",
        "generate_ids = model.generate(inputs.input_ids, max_length=60)\n",
        "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "g9UTsSR4s0ZR",
        "outputId": "84327fc5-520e-4896-d3f2-b13192db8332"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'O que √© um transistor? Como ele funciona? Qual √© a fun√ß√£o do transistor em um circuito? Por que √© importante a capacidade do circuito para o funcionamento do transistor? O que √© um circuito digital? Como um circuito digital √© constru√≠do? O que √© um'"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"O que √© um transistor?\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate\n",
        "generate_ids = model.generate(inputs.input_ids, max_length=60)\n",
        "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "EnlXoC6kqewf",
        "outputId": "084f6efd-e5be-4824-b4ed-fdb7fabe6ce2"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Um transistor √© um componente eletr√¥nico que pode ser utilizado para transferir energia. O transistor √© um componente com dois eixos de opera√ß√£o: um opera√ß√£o em regime de transi√ß√£o e outro em regime de transi√ß√£o. Quais s√£o as fun√ß√µes dos componentes eletr√¥'"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "prompt = \"Um transistor √© um componente\"\n",
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate\n",
        "generate_ids = model.generate(inputs.input_ids, max_length=60)\n",
        "tokenizer.batch_decode(generate_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CW8CK1T8tYnf",
        "outputId": "9d18f3a4-dd6f-4dbf-eb71-0a5e410647d5"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|im_start|>user\\nO que √© um transistor?<|im_end|>\\n<|im_start|>assistant\\n'"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "messages = [\n",
        "    {\"role\": \"user\", \"content\": \"O que √© um transistor?\"},\n",
        "]\n",
        "prompt = tokenizer.apply_chat_template(messages, tokenize=False, add_generation_prompt=True)\n",
        "prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "ear3hbG6uisu",
        "outputId": "d8c48f37-4a1d-4ce3-8231-af93fcc942f9"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<|im_start|>user\\nO que √© um transistor?<|im_end|>\\n<|im_start|>assistant\\n<think>\\nOkay, the user asked, \"O que √© um transistor?\" which translates to \"What is a transistor?\" I need to explain the basics of a transistor. Let me start by defining it. A transistor is a semiconductor device used to amplify or switch electronic signals. I should mention the different types, like BJT and FET, to cover the main ones. Also, important points like its function, applications, and how it works with electricity are crucial. I should keep the explanation clear and concise, avoiding technical jargon where possible. Let me check if I\\'m missing anything important here. Oh right, the user might be a student or someone new to electronics, so making sure the explanation is accurate and easy to understand is key.\\n</think>\\n\\nUm **transistor** √© um dispositivo eletr√¥nico comum utilizado para amplificar, converter ou ativar sinais el√©tricos. Ele funciona como um **fio de transi√ß√£o** e tem **um comportamento eletr√¥nico complexo**.\\n\\n### Principais caracter√≠sticas:\\n1. **Natureza semiconductor**: √â baseado em um material como sil√≠cio, que tem propriedades semicondutivas.\\n2. **Comportamento**: \\n   - **Condu√ß√£o**: Quando o capacitor √© passado por uma **voltage**, o transistor conduz a corrente.\\n   - **Invers√£o**: Quando o capacitor √© **voltage** com o transistor, a corrente √© invertida.\\n3. **Tipos**:\\n   - **Transistores de base (BJT)**: Cont√©m uma base, um semicondutor, e um **c√°todo**.\\n   - **Transistores de gate (FET)**: Cont√©m um gate, um semicondutor, e um **c√°todo**.\\n\\n### Aplica√ß√µes:\\n- **Ampuladas**: Amplifica sinais para gerar tens√µes.\\n- **Transistor de controle**: Controla a corrente em dispositivos eletr√¥nicos.\\n- **Ferramentas eletr√¥nicas**: Usado em microprocessadores, sensores e circuitos eletr√¥nicos.\\n\\n### Resumo:\\nUm transistor √© um componente semicondutivo que transmite ou inverte sinais el√©tricos com base em um campo el√©trico. Ele √© fundamental em circuitos eletr√¥nicos.<|im_end|>'"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
        "\n",
        "# Generate\n",
        "generate_ids = model.generate(inputs.input_ids, max_length=1000)\n",
        "tokenizer.batch_decode(generate_ids, skip_special_tokens=False, clean_up_tokenization_spaces=False)[0]"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "using_langgraph",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
