{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chatbot com LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carregue variáveis de ambiente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "_ = load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure o LangChain para usar o LLM desejado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(\n",
    "    model=\"llama3.2\", \n",
    "    temperature=0.0, \n",
    "    max_tokens=2000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_cerebras import ChatCerebras\n",
    "# llm = ChatCerebras(\n",
    "#     model=\"llama-3.3-70b\",\n",
    "#     temperature=0.0,\n",
    "#     max_tokens=2000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_groq import ChatGroq\n",
    "# llm = ChatGroq(\n",
    "#     model=\"qwen-qwq-32b\", \n",
    "#     temperature=0.0, \n",
    "#     max_tokens=2000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_groq import ChatGroq\n",
    "# llm = ChatGroq(\n",
    "#     model=\"llama3-70b-8192\", \n",
    "#     temperature=0.0, \n",
    "#     max_tokens=2000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from langchain_groq import ChatGroq\n",
    "# llm = ChatGroq(\n",
    "#     model=\"qwen-qwq-32b\", \n",
    "#     temperature=0.0, \n",
    "#     max_tokens=2000,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chatbot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defina o template do prompt de sistema do chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "prompt_template = \"\"\"Você é uma assistente virtual amistosa e sempre disposta a ajudar.\n",
    "Seu nome é Ana. Você atende clientes da empresa ACME.\n",
    "\n",
    "Siga sempre as instruções abaixo:\n",
    "\n",
    "- APENAS na sua primeira mensagem enviada ao cliente:\n",
    "  fale o nome do cliente e deseje 'bom dia', 'boa tarde' ou 'boa noite', de acordo com o horário atual.\n",
    "  Por exemplo: 'Bom dia, <nome do cliente>!'\n",
    "- Dê respostas concisas.\n",
    "- Utilize apenas as informações mencionadas na conversa para responder as perguntas.\n",
    "\n",
    "Informações gerais:\n",
    "\n",
    "- Horário atual: {current_time}\n",
    "- Data atual: {current_date}\n",
    "\n",
    "Informações do cliente:\n",
    "\n",
    "- Nome: José da Silva\n",
    "- Localização atual: Campinas, São Paulo\n",
    "- Comidas preferidas: vegetariana\n",
    "\"\"\"\n",
    "\n",
    "def make_system_prompt():\n",
    "    current_time = datetime.now().strftime(r\"%H:%M:%S\")\n",
    "    current_date = datetime.now().strftime(r\"%A, %Y-%m-%d\")\n",
    "    system_prompt = prompt_template.format(current_time=current_time, current_date=current_date)\n",
    "    return system_prompt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código do chatbot usando LangGraph:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "from IPython.display import Image, display\n",
    "\n",
    "class ChatbotState(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "def chatbot_node(state: ChatbotState):\n",
    "    prompt = [SystemMessage(make_system_prompt())] + state[\"messages\"]\n",
    "    response = llm.invoke(prompt)\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "builder = StateGraph(ChatbotState)\n",
    "builder.add_node(\"chatbot\", chatbot_node)\n",
    "builder.set_entry_point(\"chatbot\")\n",
    "builder.set_finish_point(\"chatbot\")\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = builder.compile(checkpointer=memory)\n",
    "\n",
    "display(Image(graph.get_graph(xray=True).draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Código para facilitar o uso do chatbot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(message: str, session_id=\"1\"):\n",
    "    config = {\"configurable\": {\"thread_id\": session_id}}\n",
    "    messages = {\"messages\": [HumanMessage(content=message)]}\n",
    "    index = -1\n",
    "    for event in graph.stream(messages, config=config, stream_mode=\"values\"):\n",
    "        for msg in event[\"messages\"][index:]:\n",
    "            msg.pretty_print()\n",
    "            print(\"\\n\")\n",
    "        index = len(event[\"messages\"])\n",
    "\n",
    "def clear_memory():\n",
    "    memory.storage.clear()\n",
    "\n",
    "def show_history(session_id=\"1\"):\n",
    "    config = {\"configurable\": {\"thread_id\": session_id}}\n",
    "    for msg in graph.get_state(config).values[\"messages\"]:\n",
    "        msg.pretty_print()\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversando com o chatbot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot(\"Olá! Você pode recomendar um restaurante?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot(\"Pensando melhor, hoje é meu aniversário e prefiro ir ao cinema primeiro. \"\n",
    "        \"Mas olha, agora estou em São José dos Campos. \"\n",
    "        \"Até pensei em ver teatro também. Eu gosto de cinema e teatro.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot(\"Bom nesse caso, preciso sacar dinheiro. Tem algum Banco do Brasil aqui perto? Eu tenho conta no banco do brasil.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chatbot(\"Você sabe em que cidade eu estou agora?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
